model:
  name: meta-llama/Meta-Llama-3-8B
  type: llama
  architecture: LlamaForCausalLM
  hidden_size: 4096
  num_layers: 32
  vocab_size: 128256
lora:
  use_lora: true
  r: 16          # Smaller rank for faster training
  alpha: 32      # Maintain 2x scaling
  dropout: 0.05
  target_modules:  # Fewer modules for speed
  - q_proj
  - v_proj
  - o_proj
  - gate_proj
training:
  epochs: 3      # Fewer epochs for faster training
  batch_size: 4  # Larger batch size for speed boost
  gradient_accumulation_steps: 2  # Maintain effective batch=8
  learning_rate: 1.0e-04  # Higher LR for faster convergence
  warmup_steps: 100  # Less warmup
  max_length: 256        # Much shorter sequences (FinQA answers are short)
  fp16: false
  bf16: true
  max_grad_norm: 1.0
validation:
  eval_steps: 1563   # After each epoch (6251/4 = ~1563 steps)
  save_steps: 1563   # Save after each epoch
  logging_steps: 200  # Regular logging
generation:
  max_new_tokens: 128
  temperature: 0.7
  top_p: 0.9
paths:
  data_dir: datasets/finqa_with_rewards
  output_dir: outputs/run_001/03_sft_llama8b
  reward_spec: outputs/run_001/02_rewards/reward_spec.yaml
metadata:
  description: Llama-3-8B-Instruct - 8B params with multi-GPU support (4x RTX 4090), matched to 1B proven settings